/*
Generated by GitHub Copilot (OpenAI model)
Description: SQS polling worker. Prioritizes high-priority queue, routes jobs to vLLM (text) or Ollama (multimodal) via OpenAI-compatible chat API, and persists user+assistant messages to DynamoDB.
Context: Run this on your local machine that has access to vLLM and Ollama endpoints.
*/

const { ReceiveMessageCommand, DeleteMessageCommand } = require('@aws-sdk/client-sqs');
const axios = require('axios');
const { createSqsClient } = require('../shared/aws');
const { appendMessages, ensureConversation } = require('../shared/historyStore');
const { createLogger } = require('../shared/logger');

const log = createLogger('worker');
const sqs = createSqsClient();

const DEFAULT_QUEUE = process.env.SQS_QUEUE_URL;
const PRIORITY_QUEUE = process.env.SQS_PRIORITY_QUEUE_URL || DEFAULT_QUEUE;

const VLLM_BASE_URL = process.env.VLLM_BASE_URL || 'http://localhost:8000';
const VLLM_MODEL = process.env.VLLM_MODEL || 'llama-3-8b-instruct';

const OLLAMA_OPENAI_BASE_URL = process.env.OLLAMA_OPENAI_BASE_URL || process.env.OLLAMA_BASE_URL || 'http://localhost:11434';
const OLLAMA_MODEL = process.env.OLLAMA_MODEL || 'llava:13b';

function sleep(ms) { return new Promise(r => setTimeout(r, ms)); }

async function pollQueueOnce(queueUrl) {
  if (!queueUrl) return null;
  const resp = await sqs.send(new ReceiveMessageCommand({
    QueueUrl: queueUrl,
    MaxNumberOfMessages: 1,
    WaitTimeSeconds: 10,
    VisibilityTimeout: 60,
  }));
  const msg = resp.Messages && resp.Messages[0];
  return msg ? { queueUrl, message: msg } : null;
}

function toOpenAIMessages(history, userMessage, images) {
  const msgs = (history || []).map(m => ({ role: m.role, content: m.content }));
  if (images && images.length > 0) {
    const content = [];
    content.push({ type: 'text', text: userMessage });
    for (const img of images) {
      const url = typeof img === 'string' ? img : (img.image_url || img.url);
      if (url) content.push({ type: 'image_url', image_url: { url } });
    }
    msgs.push({ role: 'user', content });
  } else {
    msgs.push({ role: 'user', content: userMessage });
  }
  return msgs;
}

async function callVLLM(history, userMessage) {
  const url = `${VLLM_BASE_URL.replace(/\/$/, '')}/v1/chat/completions`;
  const data = {
    model: VLLM_MODEL,
    messages: toOpenAIMessages(history, userMessage, null),
    stream: false,
    temperature: 0.3,
  };
  const r = await axios.post(url, data, { timeout: 120000 });
  const text = r.data.choices?.[0]?.message?.content || '';
  return text;
}

async function callOllama(history, userMessage, images) {
  const base = OLLAMA_OPENAI_BASE_URL.replace(/\/$/, '');
  const url = `${base}/v1/chat/completions`;
  const data = {
    model: OLLAMA_MODEL,
    messages: toOpenAIMessages(history, userMessage, images),
    stream: false,
    temperature: 0.2,
  };
  const r = await axios.post(url, data, { timeout: 180000 });
  const text = r.data.choices?.[0]?.message?.content || '';
  return text;
}

async function handleJob(job) {
  const { conversation_id, user_message, images, history, route } = job;
  if (!conversation_id || !user_message) throw new Error('Invalid job: missing fields');

  // Ensure conversation exists for stable first append
  await ensureConversation(conversation_id);

  const userMsg = { role: 'user', content: user_message, ts: new Date().toISOString() };
  let assistantText = '';
  if (route === 'ollama') {
    assistantText = await callOllama(history, user_message, images);
  } else {
    assistantText = await callVLLM(history, user_message);
  }
  const assistantMsg = { role: 'assistant', content: assistantText, ts: new Date().toISOString(), route };

  await appendMessages(conversation_id, [userMsg, assistantMsg]);
}

async function workLoop() {
  log.info('Worker started');
  while (true) {
    try {
      let polled = await pollQueueOnce(PRIORITY_QUEUE);
      if (!polled) polled = await pollQueueOnce(DEFAULT_QUEUE);
      if (!polled) { await sleep(1000); continue; }

      const { queueUrl, message } = polled;
      const body = JSON.parse(message.Body || '{}');
      log.info('Processing job', body.conversation_id, body.route);
      try {
        await handleJob(body);
        await sqs.send(new DeleteMessageCommand({ QueueUrl: queueUrl, ReceiptHandle: message.ReceiptHandle }));
        log.info('Job completed', body.conversation_id);
      } catch (err) {
        log.error('Job failed:', err.message);
        // Let message become visible again for retry
      }
    } catch (loopErr) {
      log.error('Worker loop error:', loopErr.message);
      await sleep(2000);
    }
  }
}

if (require.main === module) {
  workLoop().catch(err => {
    log.error('Worker crashed:', err.message);
    process.exit(1);
  });
}

module.exports = { workLoop };
