/*
Generated by GitHub Copilot (OpenAI model)
Description: Express wrapper to run the Lambda-style handler locally for development.
Context: Avoids relying on Moto for API Gateway; keeps local loop simple.
*/

const express = require('express');
const bodyParser = require('body-parser');
const { handler } = require('../middleware/handler');
const { createLogger } = require('../shared/logger');

const app = express();
const log = createLogger('api');

app.use(bodyParser.json({ limit: '10mb' }));

function lambdaAdapter(reqPath) {
  return async (req, res) => {
    const event = {
      version: '2.0',
      routeKey: `${req.method} ${reqPath}`,
      rawPath: reqPath,
      rawQueryString: req.url.split('?')[1] || '',
      headers: req.headers,
      queryStringParameters: req.query,
      requestContext: { http: { method: req.method, path: reqPath } },
      body: req.body ? JSON.stringify(req.body) : null,
      isBase64Encoded: false,
    };
    try {
      const result = await handler(event);
      Object.entries(result.headers || {}).forEach(([k, v]) => res.setHeader(k, v));
      res.status(result.statusCode || 200).send(result.body || '');
    } catch (err) {
      log.error('Handler error:', err.message);
      res.status(500).json({ error: err.message || 'Internal error' });
    }
  };
}

app.get('/health', lambdaAdapter('/health'));
app.get('/conversation', lambdaAdapter('/conversation'));
app.post('/chat', lambdaAdapter('/chat'));

const port = process.env.PORT || 8787;
app.listen(port, () => {
  log.info(`Local API listening on http://localhost:${port}`);
});
