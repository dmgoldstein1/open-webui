/*
Generated by GitHub Copilot (OpenAI model)
Description: SQS polling worker. Prioritizes high-priority queue, routes jobs to vLLM (text) or Ollama (multimodal) via OpenAI-compatible chat API, and persists user+assistant messages to DynamoDB.
Context: Run this on your local machine that has access to vLLM and Ollama endpoints.
*/

/*
Generated by GitHub Copilot (OpenAI model)
Description: Fixes missing import for ReceiveMessageCommand used by SQS polling.
Notes: Part of gateway/queue stability work.
*/
const { SendMessageCommand, DeleteMessageCommand, ReceiveMessageCommand } = require('@aws-sdk/client-sqs');
const axios = require('axios');
const { createSqsClient } = require('../shared/aws');
const { appendMessages, ensureConversation } = require('../shared/historyStore');
const { callVLLM, callOllama } = require('../shared/llm');
const { createLogger } = require('../shared/logger');

const log = createLogger('worker');
const sqs = createSqsClient();

const DEFAULT_QUEUE = process.env.SQS_QUEUE_URL;
const PRIORITY_QUEUE = process.env.SQS_PRIORITY_QUEUE_URL || DEFAULT_QUEUE;

function sleep(ms) { return new Promise(r => setTimeout(r, ms)); }

async function pollQueueOnce(queueUrl) {
  if (!queueUrl) return null;
  const resp = await sqs.send(new ReceiveMessageCommand({
    QueueUrl: queueUrl,
    MaxNumberOfMessages: 1,
    WaitTimeSeconds: 10,
    VisibilityTimeout: 60,
  }));
  const msg = resp.Messages && resp.Messages[0];
  return msg ? { queueUrl, message: msg } : null;
}

async function handleJob(job) {
  const { conversation_id, user_message, images, history, route } = job;
  if (!conversation_id || !user_message) throw new Error('Invalid job: missing fields');

  // Ensure conversation exists for stable first append
  await ensureConversation(conversation_id);

  const userMsg = { role: 'user', content: user_message, ts: new Date().toISOString() };
  let assistantText = '';
  if (route === 'ollama') {
    assistantText = await callOllama(history, user_message, images);
  } else {
    assistantText = await callVLLM(history, user_message);
  }
  const assistantMsg = { role: 'assistant', content: assistantText, ts: new Date().toISOString(), route };

  await appendMessages(conversation_id, [userMsg, assistantMsg]);
}

async function workLoop() {
  log.info('Worker started');
  while (true) {
    try {
      let polled = await pollQueueOnce(PRIORITY_QUEUE);
      if (!polled) polled = await pollQueueOnce(DEFAULT_QUEUE);
      if (!polled) { await sleep(1000); continue; }

      const { queueUrl, message } = polled;
      const body = JSON.parse(message.Body || '{}');
      log.info('Processing job', body.conversation_id, body.route);
      try {
        await handleJob(body);
        await sqs.send(new DeleteMessageCommand({ QueueUrl: queueUrl, ReceiptHandle: message.ReceiptHandle }));
        log.info('Job completed', body.conversation_id);
      } catch (err) {
        log.error('Job failed:', err.message);
        // Let message become visible again for retry
      }
    } catch (loopErr) {
      log.error('Worker loop error:', loopErr.message);
      await sleep(2000);
    }
  }
}

if (require.main === module) {
  workLoop().catch(err => {
    log.error('Worker crashed:', err.message);
    process.exit(1);
  });
}

module.exports = { workLoop };
